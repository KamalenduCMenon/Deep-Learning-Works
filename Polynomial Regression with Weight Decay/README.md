# Polynomial Regression with Weight Decay


This project analyzes polynomial regression models on synthetic data:

Y = cos(2Ï€X) + Z, where Z âˆ¼ N(0, ÏƒÂ²)

We evaluate the impact of model complexity (degree), sample size (N), and noise (ÏƒÂ²) on training (Ein) and testing (Eout) errors â€” with and without **L2 regularization (weight decay)**.

## ğŸ”§ Key Components
- `getData()`: Generate noisy data.
- `fitData()`: Fit polynomial regression with optional regularization.
- `getMSE()`: Compute mean squared error.
- `experiment()`: Run trials and plot average Ein/Eout.

## ğŸ” Findings
- High-degree models overfit small datasets.
- Weight decay (Î» = 0.1) improves generalization.
- Larger datasets reduce variance and testing error.

## ğŸ›  Tech
- Python, NumPy, Matplotlib
