{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SoftMax Classifier**"
      ],
      "metadata": {
        "id": "xBLnuN56DBSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "kW_XV1pDAmhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset.\n",
        "mnist = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "#print(x_train, y_train)\n",
        "#print(x_test, y_test)\n",
        "\n",
        "# Normalize pixel values.\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train, y_test = keras.utils.to_categorical(y_train, 10), keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "UP9WrJDpAmnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Softmax without dropout/Batch Normalization**"
      ],
      "metadata": {
        "id": "YepQXdU3Aedj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a softmax Model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 input images\n",
        "    keras.layers.Dense(512, activation='relu'),  # Fully connected layer with 512 units and ReLU activation\n",
        "    keras.layers.Dense(10, activation='softmax')  # Softmax activation with 10 output units (one for each digit)\n",
        "])"
      ],
      "metadata": {
        "id": "1VIPM0XrAmpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "#Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL-2jvbwBU2t",
        "outputId": "81a2bb19-801c-4e9e-ce19-f2c7a186ea98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2017 - accuracy: 0.9410 - val_loss: 0.1100 - val_accuracy: 0.9661\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0804 - accuracy: 0.9758 - val_loss: 0.0832 - val_accuracy: 0.9743\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0523 - accuracy: 0.9837 - val_loss: 0.0820 - val_accuracy: 0.9751\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 0.0622 - val_accuracy: 0.9807\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 0.0704 - val_accuracy: 0.9778\n",
            "313/313 - 1s - loss: 0.0704 - accuracy: 0.9778 - 915ms/epoch - 3ms/step\n",
            "Test accuracy: 0.9778000116348267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Softmax With Dropout**"
      ],
      "metadata": {
        "id": "kXAbAxJbErEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a softmax model with dropout\n",
        "model_dropout = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),   # Flatten the 28x28 input images\n",
        "    keras.layers.Dense(512, activation='relu'),   # Fully connected layer with 512 units and ReLU activation\n",
        "    keras.layers.Dropout(0.5),                           # Dropout layer with a dropout rate of 0.5\n",
        "    keras.layers.Dense(10, activation='softmax')  # Softmax activation with 10 output units (one for each digit)\n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "model_dropout.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "model_dropout.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "#Evaluate the model\n",
        "test_loss, test_acc = model_dropout.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy with dropout: {test_acc}\")"
      ],
      "metadata": {
        "id": "pIKPKTgpE2lu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a2d504-46d0-40f4-f879-4b84cdd3ef27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2705 - accuracy: 0.9185 - val_loss: 0.1126 - val_accuracy: 0.9662\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1367 - accuracy: 0.9592 - val_loss: 0.0887 - val_accuracy: 0.9706\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1082 - accuracy: 0.9661 - val_loss: 0.0851 - val_accuracy: 0.9733\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0933 - accuracy: 0.9708 - val_loss: 0.0705 - val_accuracy: 0.9773\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0839 - accuracy: 0.9735 - val_loss: 0.0653 - val_accuracy: 0.9799\n",
            "313/313 - 1s - loss: 0.0653 - accuracy: 0.9799 - 583ms/epoch - 2ms/step\n",
            "Test accuracy with dropout: 0.9799000024795532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Softmax with Batch Normalization**"
      ],
      "metadata": {
        "id": "PCMEw6ZngBLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a softmax model with batch normalization\n",
        "model_batchnorm = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 input images\n",
        "    keras.layers.Dense(512, activation='relu'),  # Fully connected layer with 512 units and ReLU activation\n",
        "    keras.layers.BatchNormalization(),  # Batch normalization layer\n",
        "    keras.layers.Dense(10, activation='softmax')  # Softmax activation with 10 output units (one for each digit)\n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "model_batchnorm.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "model_batchnorm.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "#Evaluate the model\n",
        "test_loss, test_acc = model_batchnorm.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy with batch normalization: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9aD3HEYgD-o",
        "outputId": "696c0cdb-2151-4c23-ee3a-45e239bddda3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1967 - accuracy: 0.9412 - val_loss: 0.1149 - val_accuracy: 0.9657\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0993 - accuracy: 0.9694 - val_loss: 0.0960 - val_accuracy: 0.9715\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0754 - accuracy: 0.9763 - val_loss: 0.0828 - val_accuracy: 0.9723\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0614 - accuracy: 0.9801 - val_loss: 0.0699 - val_accuracy: 0.9776\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 0.0703 - val_accuracy: 0.9774\n",
            "313/313 - 1s - loss: 0.0703 - accuracy: 0.9774 - 607ms/epoch - 2ms/step\n",
            "Test accuracy with batch normalization: 0.977400004863739\n"
          ]
        }
      ]
    }
  ]
}